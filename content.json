{"pages":[{"title":"About","date":"2019-08-15T09:07:03.165Z","path":"about/index.html","text":""},{"title":"Categories","date":"2019-08-15T09:07:03.170Z","path":"categories/index.html","text":""},{"title":"Tags","date":"2019-08-15T09:07:03.179Z","path":"tags/index.html","text":""}],"posts":[{"title":"大佬们的博客","date":"2019-08-27T13:38:52.000Z","path":"wiki/share-articles/","text":"友情链接 任亚鹏的博客","tags":[],"categories":[]},{"title":"分库分表","date":"2019-08-27T09:08:54.000Z","path":"wiki/mysql-split/","text":"数据库优化之分库分表 针对数据库的优化有两点，第一是从整体层面优化，设计到读写分离和分库分表。第二是从sql层面优化，主要是涉及到索引相关的一些东西。 读写分离 ​ 需求: 读写分离的目的是做数据冗余备份，同时将读写分离，提升数据库的服务性能（IO性能瓶颈）。 ​ 搭建过程: 在基本操作里面-&gt;mysql配置主从同步的步骤 。 ​ 实现原理: 首先是master数据库会先将数据库的变化存储在binlog文件中。在slave数据库上，会有一个IO Thread负责将binlog文件读取到内部的relaylog文件中。同时，slave数据库上的另外一个线程SQL Thread读取relaylog，将数据写入到slave数据库里面。 ​ 细节: mysql的binlog文件存储在 /var/lib/mysql文件夹下；使用命令-&gt; mysqlbinlog –base64-output=decode-rows -v mysql-bin.000001 查看binlog的内容；binlog的格式：statement（默认，基于sql语句模式，针对数据更新的一些函数now()等，数据延迟造成的不一致），row：基于行模式，记录修改后每一条数据变化的值，mixed：混合模式，由mysql自动判断处理。 ​ 问题：同步延迟，master tps较高时出现同步延迟； 网络延迟；磁盘IO 分库分表 ​ 垂直拆分 ​ 概念:垂直拆分主要是通过业务层面，将各个业务模块所使用到的表放到各自不同的数据库里面，做到各个业务模块库相互隔离的目的。 ​ 问题:若是各个业务模块的表之间存在一些关联查询，需要将这些查询改为服务调用的方式。 针对一些全局表，可以改为服务调用的方式，对外提供服务。 ​ 水平拆分 ​ 概念:将一张大的表拆分成n多张小表。实现方式，第一种是通过一致性hash（若是新增表的话，会涉及到数据迁移的问题）。第二种是可以按照id的范围来拆分。第三种是通过日期来拆分。 ​ 问题:唯一主键问题，可以使用zk自增id 可以使用redis的自增id 可以使用代理的id Mycat 1. 从github上面clone项目 https://github.com/MyCATApache/Mycat-Server.git2. 修改项目中schema.xml配置文件中的dataHost数据库配置节点信息，修改为可用的数据库3. MycatStartup类运行main函数启动 idea启动前需要在配置参数VM options: -DMYCAT_HOME=D:\\code\\Mycat-Server\\src\\main4. 通过数据库连接工具可以连接到MyCat,数据库相关配置在server.xml配置文件里面 默认的用户名: root 密码: 123456 port: 80665. mycat里面有三个比较重要的配置文件 server.xml 配置数据库连接相关的一些信息 schema.xml 配置数据库的一些节点信息 rule.xml 配置一些路由规则","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"数据库","slug":"java/数据库","permalink":"https://gzl2017.github.io/categories/java/数据库/"},{"name":"mysql","slug":"java/数据库/mysql","permalink":"https://gzl2017.github.io/categories/java/数据库/mysql/"}]},{"title":"基本操作","date":"2019-08-27T09:08:25.000Z","path":"wiki/mysql-base/","text":"centos7上mysql的安装步骤 1.下载mysql的repo源 &gt; wget http://repo.mysql.com/mysql57-community-release-el7-8.noarch.rpm2.安装源&gt; rpm -ivh mysql57-community-release-el7-8.noarch.rpm3.安装数据库-&gt;yum install mysql-server4.启动数据库&gt; systemctl start mysqld5.查看mysql为root账号生成的随机密码&gt;grep \"password\" /var/log/mysqld.log 说明root@localhost:此处为随机密码6.运行mysql -uroot -p回车7.粘贴随机密码-&gt;此时已经登录到mysql数据库，需要为root账号设置密码8.由于mysql5.7有对密码设置的验证，简单密码设置不了，需要运行下面两条命令关闭验证 &gt; set global validate_password_length=1; &gt; set global validate_password_policy=0;9.修改root账号的密码 &gt; set password = password('123456');10.修改root账号的权限 &gt; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION;11.可以创建一个其它的用户 &gt; create user repl identified by 'repl';12.为该用户授权 &gt; grant replication slave on *.* to 'repl'@'%' identified by 'repl';(数据同步的权限) &gt; GRANT ALL ON *.* TO 'pig'@'%';(为用户pig授予所有权限) mysql配置主从同步的步骤 1.在master服务器上创建一个可以进行数据同步的账户。 &gt; create user repl identified by 'repl';2.在master服务器上为该用户授权。 &gt; grant replication slave on *.* to 'repl'@'%' identified by 'repl';3.在master服务器上修改/etc/my.cnf文件。 [mysqld] log-bin=mysql-bin server-id=1474.在master上面重启mysql &gt; systemctl restart mysqld5.在master上登录数据库，使用下面命令查看二进制文件。 &gt; show master status;6.在slave服务器上修改/etc/my.cnf文件 [mysqld] server-id=149 relay-log=slave-relay-bin relay-log-index=slave-relay-bin.index read-only=17.在slave服务器上重启mysql &gt; systemctl restart mysqld8.在slave上登录数据库, 执行下列命令，设置master相关参数。 &gt; change master to master_host='192.168.25.147',master_port=3306,master_user='repl',master_password='repl',master_log_file='mysql-bin.000003', master_log_pos=154;9.在slave上运行命令，启动服务 &gt; start slave;10.查看状态，查看主从同步设置是否成功 &gt; show slave status\\G;11.搭建完成，现在就可以玩啦，尝试在master上面创建数据库和表，在slave上会看到相应的数据库和表。","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"数据库","slug":"java/数据库","permalink":"https://gzl2017.github.io/categories/java/数据库/"},{"name":"mysql","slug":"java/数据库/mysql","permalink":"https://gzl2017.github.io/categories/java/数据库/mysql/"}]},{"title":"索引","date":"2019-08-27T09:08:17.000Z","path":"wiki/mysql-index/","text":"1.数据库四大特性 ​ A( Atomicity 原子性): 数据库最小的工作单元，整个工作单元要么一起提交成功,要么一起失败回滚。​ C( Consistency 一致性): 事物中操作的数据的状态是一致的。即写入数据的结果必须完全符合预设的规则，不会因为出现系统意外等原因导致状态的不一致。​ I( Isolation 隔离性): 一个事务所操作的数据在提交之前，对其他事务的可见性设定（一般设定为不可见）。​ D( Durability 持久性): 数据库的数据一旦提交,无法更改。 2.多个事物并发引起的数据读取问题 ​ 脏读: 是指一个事物读取到了另外一个事物未提交的数据。​ 不可重复读: 是指在一个事物未结束之前, 前后两次读取到的数据不一致现象。原因在于该事物在前后两次读取数据之间，另外一个事物修改了该数据。(不可重复读的重点在于修改)。​ 幻读: 是指当一个事物修改了数据库表中某一个范围内的数据的某一个字段，但是另外一个事物在此期间又在该范围内插入了一条新的数据，造成前一个事物出现幻觉(没有完全修改)。(幻读的重点在于新增或删除) 。 3.数据库事物的隔离级别 Read Uncommited 读未提交: 事物未提交对其它的事物也是可见的。 Read Commited 读已提交: 一个事物只能够读取到已提交的数据。(解决脏读, 未解决不可重复读)。 Repeatable Read 可重复读: 一个事物对数据的前后读取结果是一致的。(解决了不可重复读, 未解决幻读)。 Serializable 串行化: 数据库最高的隔离级别, 强制所有事物串行执行,解决了所有并发问题。 4.聚集索引和非聚集索引的区别 聚集索引: 表中的数据是按照索引的顺序来存储的。索引的叶子节点上存储了真实的数据,不会有另外单独的数据页。 非聚集索引: 表中的数据存储不依赖于索引的顺序。索引的叶子节点上存储了索引的关键字和指向真实数据的指针。 5.sql调优 ​ a. 创建索引 b.使用临时表存储中间结果-&gt;(避免多次扫描主表)。c. 避免在索引上使用计算。4.少使用select *，只返回需要的字段。 6.如何理解MVCC ​ a. 数据库每张表会单独维护两个字段，数据行版本号和删除版本号。 ​ b. 当执行insert操作时，我们开启了一个事物，执行数据插入操作时，会将这个事物的事物id设置到数据行版本号这个字段中（这个事物的事物id属于数据库一个全局属性，自增）。 ​ c. 当执行delete操作时，我们开启了一个事物，执行数据删除操作时，会将这个事物的事物id设置到删除版本号这个字段中。 ​ d. 当执行update操作时，我们开启了一个事物，指定数据更新操作时，会将这行数据copy一份，copy的这份数据数据行版本号为当前事物id，删除版本号为Null，并更新相关字段。原先那行的删除版本号会被设置为当前的事物id。 ​ e. 当我们执行数据库查询时，满足以下两点要求： ​ e1：查找数据的数据行版本号小于或等于当前事物id。(保证该条数据在当前事物开启之前就已经存在或者为该事物添加的数据。 ​ e2：查找数据的删除版本号为Null或者删除版本号大于当前事物id。（该条规则可以确保当前事物在开始之前数据还未被删除。 7.MVCC解决的问题与未解决的问题 若是一个查询先于一行的数据更新，不会出现问题。若是一个查询后于一行的数据更新，会产生脏读的问题。 8.Innodb数据库的四种隔离级别是如何实现的 ​ 读未提交：对select操作不会加锁，并发性能是最好的，但是容易造成脏读。 ​ 读已提交（互联网上默认的隔离级别）：普通的数据读取是会直接读取数据快照，加锁的select，update等操作会使用记录锁。注意：读已提交读取快照时，一个事物读取了数据，但是当第二次读取的时候，另外一个事物已经将该快照刷新了，所以会造成不可重复读的问题。 ​ 可重复读（Innodb默认的事物隔离级别）：对于普通的数据库查询，使用读取快照的方式。对于加锁的select,update等语句，他们加锁的力度取决于查询条件是使用了唯一索引还是使用了范围查询。若是使用了唯一索引，会使用记录锁的方式。若是使用了范围查询，会使用间隙锁，避免发生不可重复读。注意:当一个事物开启读取数据时，前后两次读取的都是同一个快照，这样就可以实现了可重复读。 ​ 串行化：针对所有的操作都会去加锁，普通的select操作会去加共享锁-&gt;select * from table in share mode。对于 update 等操作会加排他锁。若是一个事物查询操作时，正好有一个事物对改行的数据做修改操作。则该查询操作会阻塞，直到更新操作执行完成。 9.如何理解快照读和当前读 ​ 快照读：读取的数据是快照。当前读：读取的数据是数据库的最新的数据。","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"数据库","slug":"java/数据库","permalink":"https://gzl2017.github.io/categories/java/数据库/"},{"name":"mysql","slug":"java/数据库/mysql","permalink":"https://gzl2017.github.io/categories/java/数据库/mysql/"}]},{"title":"tcp","date":"2019-08-26T13:33:14.000Z","path":"wiki/tcp/","text":"此时握手 四次挥手 为什么要三次握手 为什么要四次挥手","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"分布式","slug":"java/分布式","permalink":"https://gzl2017.github.io/categories/java/分布式/"},{"name":"协议","slug":"java/分布式/协议","permalink":"https://gzl2017.github.io/categories/java/分布式/协议/"}]},{"title":"project-ask","date":"2019-08-26T13:26:32.000Z","path":"wiki/project-ask/","text":"面试真题 给你一张表，表示面name字段有重复的，现要求删除重复的，只保留一条，保留的数据是id最小的那条数据，如何做，生产系统中如何做? 在项目中都遇到过哪些的技术难点，如何解决的？ 说说你们在dubbo中是如何解决分布式事物的（看过dubbo，但貌似没有讲到过解决分布式事物这） 说说你对分布式的理解 项目专题 催收系统 ​ 任务执行流程 从原始借据表bp_collect_loan_src中获取某个批次的原始借据总数，最小id，最大id。 会有一个数量限制，若是当前批次的原始借据数目小于10000，直接调用更新借据的操作。 若是当前这个批次的原始借据数目大于10000，获取到线程池，分批次将这些任务放到线程池，每个线程调用 更新借据的操作。 更新借据的逻辑，通过原始借据id从小到大查询原始借据，每次500条。（重试机制，当查询出现异常时，重 新查询）。 将查询到的这批原始借据加工成为催收系统里面的借据。bp_collect_loan_src –&gt; bp_collect_loan。 调用bp_collect_loan表操作mapper的insertOrUpdate方法将原始借据插入或更新到系统中。 bp_collect_loan会针对客户计算出一个hash值，作为bp_collect_loan的loadId，loadId在借据表中作为唯一 索引，当有数据的时候会更新，没有数据的时候会最添加。 上游每天会更新他们的借据信息，我们在这边只是做一个数据同步的功能。","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"项目","slug":"java/项目","permalink":"https://gzl2017.github.io/categories/java/项目/"}]},{"title":"threadpool","date":"2019-08-26T13:20:13.000Z","path":"wiki/threadpool/","text":"线程池 // 创建线程池的工具类Executorspublic class Executors &#123; // 创建一个只有一个工作线程的线程池 public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; // 创建一个固定数目线程的线程池(核心线程数和最大线程数相同) public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; // 创建一个cache线程池，核心线程大小为0 public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; // 线程工厂，负责为线程池中的Worker创建线程-》可以创建个性化的线程 static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; &#125; public Thread newThread(Runnable r) &#123; // 返回的线程又将Worker做了一层封装,当该线程执行strart方法时,将会调用Worker的run方法 Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125; &#125; &#125;// jdk定义的线程池public class ThreadPoolExecutor extends AbstractExecutorService &#123; // 核心线程数 private volatile int corePoolSize; // 最大线程数 private volatile int maximumPoolSize; // 阻塞队列 private final BlockingQueue&lt;Runnable&gt; workQueue; // 非工作线程存活时间 private volatile long keepAliveTime; // 创建线程的工厂 private volatile ThreadFactory threadFactory; // 线程池的拒绝策略 private volatile RejectedExecutionHandler handler; // 存储创建好的Worker线程 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); // 主锁,对workers进行操作时会上锁 private final ReentrantLock mainLock = new ReentrantLock(); // 定义线程池内部的工作线程 private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; // 当前Worker持有的线程 final Thread thread; // 当前Worker执行的第一个任务 Runnable firstTask; // 记录当前Worker已经完成的任务数量 volatile long completedTasks; Worker(Runnable firstTask) &#123; // 将aqs中的state值由0设置为-1,禁止中断(上锁了) setState(-1); this.firstTask = firstTask; // 调用工厂为当前的Worker创建一个Thread—&gt;传入的是当前this对象 this.thread = getThreadFactory().newThread(this); &#125; // 当前Worker线程启动需要执行的方法，该方法会由内部属性thread调用start方法时触发。 public void run() &#123; runWorker(this); &#125; // 判断线程是否被独占 protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; // 尝试获取锁 protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125; &#125; // Worker线程执行的真正逻辑 final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock();//执行任务之前允许被打断 boolean completedAbruptly = true; try &#123; // 当前worker的task不为null或者是阻塞队列不为null,worker线程会一直运行 while (task != null || (task = getTask()) != null) &#123; // 上锁 w.lock(); if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; // 调用worker的run方法 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125; &#125; // 初始化一个线程池 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; // 1.若是当前工作线程数小于核心线程数, 会去创建一个核心线程。 // 2.若是当前工作线程数大于等于核心线程数，将任务放入到阻塞队列。 // 3.若是阻塞队列已满，会去创建非核心线程。 // 4.若是创建非核心线程也失败，执行拒绝策略。 public void execute(Runnable command) &#123; int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; // 1.尝试着将工作线程数加1，workers的个数。 // 2.创建一个Worker线程，并将其加入到workers数组中。 // 3.若是加入到workers数组成功，调用worker的thread的start方法，启动线程。 // 4.线程启动之后，会调用worker的run方法，而run方法又是调用runWorker(this)方法来执行的。 private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: // 自旋 for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); if (runStateOf(c) != rs) continue retry; &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) throw new IllegalThreadStateException(); // 将创建好的Worker加入到workers数组中 workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted; &#125; &#125;// spring线程池-&gt;ThreadPoolTaskExecutorpublic class ThreadPoolTaskExecutor &#123; private final Object poolSizeMonitor = new Object(); // 核心线程数 private int corePoolSize = 1; // 最大线程数 private int maxPoolSize = 2147483647; // 非核心线程空闲最大存活时间 private int keepAliveSeconds = 60; // 缓存队列容量 private int queueCapacity = 2147483647; // 是否允许核心线程池超时等待(设置为false,当到达一定时间没有任务,线程池会自动关闭) private boolean allowCoreThreadTimeOut = false; private TaskDecorator taskDecorator; private ThreadPoolExecutor threadPoolExecutor; public ThreadPoolTaskExecutor() &#123; &#125; // 因为spring线程池提供了更加灵活的配置，项目中一般使用的是spring的线程池。","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"并发","slug":"java/并发","permalink":"https://gzl2017.github.io/categories/java/并发/"},{"name":"线程池","slug":"java/并发/线程池","permalink":"https://gzl2017.github.io/categories/java/并发/线程池/"}]},{"title":"lock","date":"2019-08-25T06:28:41.000Z","path":"wiki/lock/","text":"前戏java里面提供了两种锁机制，基于jvm层面实现的关键字synchronized和基于jdk层面实现的Lock锁。 synchronized关键字 基本使用：synchronized关键字可以用来修饰静态方法，普通方法，代码块，获取到的锁对象分别为当前类Class对象，当前实例对象和synchronized括号里面的对象。 加锁原理：synchronized加锁是基于对象监视器Monitor的monitorenter和monitorexit。在java中，每个对象都会有一个对象监视器，当synchronized修饰代码块时，在开始位置会加上monitorenter指令，在方法结束和异常处会插入monitorexit指令。当执行monitorentrt指令时，会去获取锁的Monitor对象，若是获取到，执行，获取不到的话，线程阻塞。 synchronized的锁升级 ​ 偏向锁：当线程执行时，会去修改对象的对象头（Mark Word）中线程id，若是修改成功，执行。若是修改不成功，需要将偏向锁升级为轻量级锁。锁升级的过程是，该获取锁的线程通知Mark Word中标识的线程，使其进入暂停状态。 ​ 轻量级锁：争抢锁的线程会去将对象的对象头（Mark Word）拷贝的线程栈中，并将对象头指向该栈（cas操作），若是执行成功，获取到锁，执行代码。若是执行失败，自旋等待其它线程释放锁。 ​ 重量级锁：当自旋超过了一定的时间之后，若是还不能获取到锁，将会升级为重量级锁，线程阻塞。 Lock接口 特性 描述 尝试非阻塞的获取锁 当前线程尝试获取锁，若这一时刻锁没有被其它线程获取到，则成功获取并持有锁。 能被中断的获取锁 获取到锁的线程能够响应中断，当获取到锁的线程被中断时，中断异常将会被抛出，同时锁会被释放。 超时获取锁 在指定的时间之前获取锁，如果过了指定的时间任然无法获取到锁，则返回。 方法名称 描述 void lock() 线程获取锁，当获取到锁后，线程从该方法返回。 void lockInterruptibly() throws InteruptedExecption 与lock方法不同之处在于可以在获取锁的过程中中断当前的线程。 boolean tryLock() 尝试获取锁，获取到返回true，未获取到返回false。 boolean tryLock(long time, TimeUnit unit) throws InteruptedException; 尝试获取锁，下列三种情况下会返回：1.在指定的时间内获取到锁。2.过了超时时间为获取到锁。3.当前线程被中断。 void unlock() 释放锁 Condition newCondition() 获取等待通知组件，只有成功获取到了锁，才能创建该组件 lock和synchronized的区别 ​ 关于加锁和释放锁方式和原理的不同 synchronized是jvm层面提供的关键字，获取锁和释放锁不需要手工干预。synchronized获取锁时会获取锁定对象(静态方法-&gt;类对象，普通方法-&gt;当前对象，代码块-&gt;提供的对象)的对象监视器Monitor。一旦一个线程获取到这个对象的Monitor,其它线程就无法获取。但是同一个线程对这个Monitor可以多次获取（可重入）。对于锁的释放，当方法正常执行结束或者发生异常时，会释放该锁。 lock锁是jdk层面提供的锁，可以基于api执行上锁和解锁操作，操作更加的灵活。Lock接口实现的可重入锁ReentLock，其底层是依赖于AQS实现，AQS内部维护了一个同步队列，获取锁的线程会被加入到这个同步队列上面，等待前一个获取锁的节点释放锁时唤醒。ReentLock提供了多种获取锁的方式，可以在获取锁的时候立即响应中断。 关于等待队列和同步队列的不同 synchronized基于对象监视器，调用底层的wait方法时，会将线程加入到等待队列中，内部只维护了一个等待队列，而调用notify或者notifyAll时，会将唤醒的线程加入到同步队列。 ReentLock内部可以创建多个等待队列，可以调用await方法将获取到锁的线程加入到等待队列，也可以调用singal,singalAll唤醒线程，将其加入到同步队列中。","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"并发","slug":"java/并发","permalink":"https://gzl2017.github.io/categories/java/并发/"},{"name":"锁","slug":"java/并发/锁","permalink":"https://gzl2017.github.io/categories/java/并发/锁/"}]},{"title":"http","date":"2019-08-24T01:51:41.000Z","path":"wiki/http/","text":"对http协议的理解 ​ http协议是一种基于客户端-&gt;服务器模式的协议，客户端发送请求，服务器返回响应。http协议通过uri定位访问的资源。http协议是一种无状态的协议，服务 器无法识别同一浏览器的前后两次请求（为解决无状态,浏览器端引入了cookie机制）。 http响应状态码 状态码 类别 原因短语 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误） 服务器无法处理请求 5XX Server Error （服务端错误） 服务器处理请求出错 http请求首部常用字段 Accept：用户代理可处理的媒体类型。 Accept-Encoding：优先的内容编码。 Accept-Language：优先的语言。 Content-Type：实体类型。 跨域问题","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"分布式","slug":"java/分布式","permalink":"https://gzl2017.github.io/categories/java/分布式/"},{"name":"协议","slug":"java/分布式/协议","permalink":"https://gzl2017.github.io/categories/java/分布式/协议/"}]},{"title":"io","date":"2019-08-23T09:43:24.000Z","path":"wiki/io/","text":"1.在jdk1.4，java引入了nio，nio是一种非阻塞io。 在nio中有三个概念 缓冲区(buffer)：java nio中数据的读取和存放需要通过缓冲区。 通道(channel)：可以理解为io中流的概念 ，与流不同的是，一个通道中既可以进行数据的读取，也可以进行数据的写入，而在io模型中，数据的读取和写入会有专门的输入和输出流来进行操作。 选择器(select)：通道可以在选择器上注册相关的事件，而选择器会有一个专门的线程来负责轮询这些事件，当某个写入事件或是读取事件可写或可读时，会交给相应的线程来处理。 通过java nio模拟一个服务端-客户端通信的实例 /** * NIO Server服务 */class NIOServer&#123; // Selector-&gt;注册channel Selector selector = null; // ServerSocketChannel-&gt;服务端channel,类似ServerSocket ServerSocketChannel serverSocketChannel; // 处理selector轮询事件 private ChannelHandle handle; // NIO服务关闭标识 private volatile boolean stop = false; NIOServer(int port) &#123; try &#123; selector = Selector.open(); serverSocketChannel = ServerSocketChannel.open(); // 设置channel为非阻塞模式 serverSocketChannel.configureBlocking(false); // 为channel绑定端口 serverSocketChannel.bind(new InetSocketAddress(port)); // 将channel注册到selector上，监听连接事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); handle = new ChannelHandle(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 启动服务 * @throws IOException */ public void start() throws IOException &#123; while (!stop) &#123; // 获取到等待处理的IO事件数量 int readyChannels = selector.select(); // 若是等待处理的IO事件数量为0,不处理 if (readyChannels == 0) &#123; continue; &#125; Iterator&lt;SelectionKey&gt; iterator = selector.selectedKeys().iterator(); // 处理这些SelectionKey while (iterator.hasNext()) &#123; // 获取到该key SelectionKey key = iterator.next(); // 移除该key iterator.remove(); // 分别处理各自事件 if (key.isAcceptable()) &#123; handle.handleAccept(key); &#125; else if (key.isReadable()) &#123; handle.handleRead(key); &#125; else if (key.isWritable()) &#123; handle.handleWrite(key); &#125; &#125; &#125; &#125; // 停止该服务 public void stop() &#123; this.stop = true; &#125;&#125;/** * 针对selector上不同事件的处理类 */class ChannelHandle &#123; /** * 处理连接事件 * @param key * @throws IOException */ public void handleAccept(SelectionKey key) throws IOException &#123; ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel sc = ssc.accept(); sc.configureBlocking(false); sc.register(key.selector(), SelectionKey.OP_READ); &#125; /** * 处理可读事件 * @param key * @throws IOException */ public void handleRead(SelectionKey key) throws IOException &#123; SocketChannel sc = (SocketChannel) key.channel(); // fixme 对读取到的数据进行处理-&gt;相关协议解析 sc.register(key.selector(), SelectionKey.OP_WRITE); &#125; /** * 处理可写事件 * @param key * @throws IOException */ public void handleWrite(SelectionKey key) throws IOException &#123; System.out.println(\"处理写数据\"); // fixme 对输出结果按照相关协议进行封装 String header = \"HTTP/1.1 200 OK\\r\\n\"; StringBuffer result = new StringBuffer(header); result.append(\"Content-Type:application/json\\n\"); result.append(\"\\r\\n\"); result.append(\"hello,world\"); SocketChannel channel = (SocketChannel)key.channel(); ByteBuffer wrap = ByteBuffer.wrap(result.toString().getBytes()); channel.write(wrap); channel.close(); &#125;&#125;// 调用类public class NIOUtil &#123; public static void main(String[] args) &#123; // 启动一个基于NIO的服务 NIOServer nioServer = new NIOServer(8070); try &#123; nioServer.start(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 下面是通过java io的方式来实现的 public class IOUtil &#123; public static void main(String[] args) &#123; IOServer.createServer(); &#125;&#125;class IOServer &#123; private static volatile boolean stop = false; /** * 开启服务 */ static void createServer() &#123; ExecutorService executorService = Executors.newFixedThreadPool(3); ServerSocket serverSocket = null; try &#123; serverSocket = new ServerSocket(8090); System.out.println(\"服务器在端口8090上启动。。。\"); while (!stop) &#123; try &#123; Socket socket = serverSocket.accept(); // 将任务提交给线程池来处理 executorService.execute(new SocketHandle(socket)); &#125; catch (Exception e) &#123; e.printStackTrace(); break; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (serverSocket != null) &#123; serverSocket.close(); &#125; executorService.shutdown(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 关闭服务 */ static void stopServer() &#123; stop = true; &#125;&#125;/** * socket处理线程类 */class SocketHandle implements Runnable &#123; private Socket socket; SocketHandle(Socket socket) &#123; super(); this.socket = socket; &#125; @Override public void run() &#123; // 处理输入 InputStream is = null; InputStreamReader isr = null; BufferedReader br = null; try &#123; is = socket.getInputStream(); isr = new InputStreamReader(is); br = new BufferedReader(isr); String s = null; while ((s = br.readLine()) != null &amp;&amp; s.length() &gt; 0) &#123; System.out.println(s); s = null; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; &#125; // 处理输出 \\r\\n 回车换行 OutputStream os = null; try &#123; os = socket.getOutputStream(); os.write(\"HTTP/1.1 200 OK\\r\\n\".getBytes()); os.write(\"Content-Type:application/json\\n\".getBytes()); os.write(\"\\r\\n\".getBytes()); os.write(\"hello,world\".getBytes()); os.flush(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (socket != null) &#123; try &#123; socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125;","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"io","slug":"java/io","permalink":"https://gzl2017.github.io/categories/java/io/"}]},{"title":"thread","date":"2019-08-21T05:43:50.000Z","path":"wiki/thread/","text":"为什么使用多线程 ​ 更多的处理器核心 更快的响应时间 更好的编程模型 线程的六种状态 状态 状态说明 NEW 初始状态，线程已经被构建，但是没有调用start()方法。 RUNNABLE 线程处于运行状态或者是可运行状态。 BLOCKED 阻塞状态，表示当前线程等待获取锁。 WAITING 等待状态，需要其他线程唤醒。 TIME_WAITING 超时等待状态，需要其他线程唤醒或者过了超时时间自动唤醒。 TERMINATED 终止状态，表示当前线程已经运行结束。 如何查看线程信息 ​ jps:该命令可以获取进程id。 ​ jstack:使用 jstack 进程id，可以查看线程的一些信息。 线程的初始化 private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; if (name == null) &#123; throw new NullPointerException(\"name cannot be null\"); &#125; this.name = name; // 创建的这个线程的父线程就是当前的这个线程 Thread parent = currentThread(); SecurityManager security = System.getSecurityManager(); if (g == null) &#123; if (security != null) &#123; g = security.getThreadGroup(); &#125; if (g == null) &#123; g = parent.getThreadGroup(); &#125; &#125; g.checkAccess(); if (security != null) &#123; if (isCCLOverridden(getClass())) &#123; security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION); &#125; &#125; g.addUnstarted(); // 设置当前线程的线程组信息 this.group = g; // 将daemon priority设置为父线程的相关属性 this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; setPriority(priority); if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); this.stackSize = stackSize; tid = nextThreadID();&#125; 如何优雅的终止线程 ​ 使用volidate修饰的变量 中断线程interrupt()方法 在class所在目录下，使用javap -v HelloWorld.class指令可以查看该class的信息 管道输入输出流–&gt;用于线程之间数据的传输，传输媒介为内存 ​ PipedInputStream ​ PipedOutputStram ​ PipedReader ​ PipedWriter","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"并发","slug":"java/并发","permalink":"https://gzl2017.github.io/categories/java/并发/"},{"name":"基础","slug":"java/并发/基础","permalink":"https://gzl2017.github.io/categories/java/并发/基础/"}]},{"title":"springboot","date":"2019-08-21T01:58:17.000Z","path":"wiki/springboot/","text":"// AutoConfigurationImportSelectorpublic String[] selectImports(AnnotationMetadata annotationMetadata) &#123; // 判断自动装配是否开启，读取环境变量中spring.boot.enableautoconfiguration的属性值 if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; // 获取到autoConfigurationMetadata AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());&#125;protected AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata,AnnotationMetadata annotationMetadata) &#123; // 做了重复判断 if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; // 获取到@EnableAutoConfiguration注解上的相关属性值exclude excludeName AnnotationAttributes attributes = getAttributes(annotationMetadata); // 获取到需要自动装配的类的全限定名集合 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); // 将互选名单先进行去重 configurations = removeDuplicates(configurations); // 获取需要排除的自动装配项exclude excludeName或者是环境变量中获取 Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); // 将需要排除的自动装配项移除 configurations.removeAll(exclusions); // 过滤掉相关的装配项 configurations = filter(configurations, autoConfigurationMetadata); // 触发自动装配组件的导入事件 fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions);&#125;protected AnnotationAttributes getAttributes(AnnotationMetadata metadata) &#123; // 获取到EnableAutoConfiguration注解的全限定名 // org.springframework.boot.autoconfigure.EnableAutoConfiguration String name = getAnnotationClass().getName(); // 获取该@EnableAutoConfiguration注解上的exclude和excludeName属性 AnnotationAttributes attributes = AnnotationAttributes.fromMap(metadata.getAnnotationAttributes(name, true)); Assert.notNull(attributes, () -&gt; \"No auto-configuration attributes found. Is \" + metadata.getClassName() + \" annotated with \" + ClassUtils.getShortName(name) + \"?\"); return attributes;&#125;// 通过spring的spi机制SpringFactoriedLoader加载需要自动装配的候选组件类全限定名protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); return configurations;&#125;// 获取被排除在外的类全限定名protected Set&lt;String&gt; getExclusions(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; Set&lt;String&gt; excluded = new LinkedHashSet&lt;&gt;(); excluded.addAll(asList(attributes, \"exclude\")); excluded.addAll(Arrays.asList(attributes.getStringArray(\"excludeName\"))); excluded.addAll(getExcludeAutoConfigurationsProperty()); return excluded;&#125;// 从环境变量中获取spring.autoconfigure.exclude属性的值private List&lt;String&gt; getExcludeAutoConfigurationsProperty() &#123; if (getEnvironment() instanceof ConfigurableEnvironment) &#123; Binder binder = Binder.get(getEnvironment()); return binder.bind(PROPERTY_NAME_AUTOCONFIGURE_EXCLUDE, String[].class).map(Arrays::asList).orElse(Collections.emptyList()); &#125; String[] excludes = getEnvironment().getProperty(PROPERTY_NAME_AUTOCONFIGURE_EXCLUDE, String[].class); return (excludes != null) ? Arrays.asList(excludes) : Collections.emptyList();&#125;// 对配置项执行过滤的方法private List&lt;String&gt; filter(List&lt;String&gt; configurations, AutoConfigurationMetadata autoConfigurationMetadata) &#123; long startTime = System.nanoTime(); String[] candidates = StringUtils.toStringArray(configurations); boolean[] skip = new boolean[candidates.length]; boolean skipped = false; // 关键点-&gt;getAutoConfigurationImportFilters() for (AutoConfigurationImportFilter filter : getAutoConfigurationImportFilters()) &#123; invokeAwareMethods(filter); boolean[] match = filter.match(candidates, autoConfigurationMetadata); for (int i = 0; i &lt; match.length; i++) &#123; if (!match[i]) &#123; skip[i] = true; candidates[i] = null; skipped = true; &#125; &#125; &#125; if (!skipped) &#123; return configurations; &#125; List&lt;String&gt; result = new ArrayList&lt;&gt;(candidates.length); for (int i = 0; i &lt; candidates.length; i++) &#123; if (!skip[i]) &#123; result.add(candidates[i]); &#125; &#125; return new ArrayList&lt;&gt;(result);&#125;// AutoConfigurationImportFilter实现类加载protected List&lt;AutoConfigurationImportFilter&gt; getAutoConfigurationImportFilters() &#123; return SpringFactoriesLoader.loadFactories(AutoConfigurationImportFilter.class, this.beanClassLoader);&#125; // SpringFactoriesLoaderpublic static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, @Nullable ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); // 第一步:获取所有列表 第二步:获取指定key的列表 return loadSpringFactories(classLoader).getOrDefault(factoryClassName, Collections.emptyList());&#125;// classLoader属性值可以为nullpublic static &lt;T&gt; List&lt;T&gt; loadFactories(Class&lt;T&gt; factoryClass, @Nullable ClassLoader classLoader) &#123; // classLoader未指定,使用默认的classLoader ClassLoader classLoaderToUse = classLoader; if (classLoaderToUse == null) &#123; classLoaderToUse = SpringFactoriesLoader.class.getClassLoader(); &#125; // 调用loadFactoryNames加载指定key的扩展 List&lt;String&gt; factoryNames = loadFactoryNames(factoryClass, classLoaderToUse); List&lt;T&gt; result = new ArrayList&lt;&gt;(factoryNames.size()); for (String factoryName : factoryNames) &#123; result.add(instantiateFactory(factoryName, factoryClass, classLoaderToUse)); &#125; AnnotationAwareOrderComparator.sort(result); return result;&#125;","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"springboot","slug":"java/springboot","permalink":"https://gzl2017.github.io/categories/java/springboot/"}]},{"title":"spring","date":"2019-08-19T09:04:07.000Z","path":"wiki/spring/","text":"此处参考了http://www.codeceo.com/article/spring-transactions.html这篇博客，总结的挺nice的。 spring事物简介 spring基于注解的事物 ​ xml文件开启注解驱动，相关类和方法上通过@Transactional注解标识。 ​ spring在启动是会为这些class生成spring内部管理的bean，若是发现带有@Transactional注解的类和方 ​ 法，会为其生成代理类，代理类中会做相关的事物处理（正常提交，异常回滚）。 基于实现TransactionCallback接口的事物 ​ spring事物的传播属性 常量名称 常量解释 PROPAGATION_REQUIRED(propagation_required) 支持当前事物，如果当前没有事物，就新建一个事物。这是最常见的选择，也是spring默认的事物传播。 PROPAGATION_REQUIRES_NEW(propagation_requires_new) 新建事物，如果当前存在事物，就把当前事物挂起。新建的事物和挂起的事物没有任何的关系，是两个独立的事物。外层事物失败回滚之后，不能回滚内层事物执行的结果。内层事物失败抛出异常，外层事物捕获，也可以不处理回滚操作。 PROPAGATION_SUPPORTS(propagation_supports) 支持当前事物，如果当前没有事物，就以非事物的方式执行。 PROPAGATION_MANDATORY(propagation_mandatory) 支持当前事物，如果当前没有事物，就抛出异常。 PROPAGATION_NOT_SUPPORTED(propagation_not_supported) 以非事物方式执行操作，如果当前存在事物，就把当前事物挂起。 PROPAGATION_NEVER(propagation_never) 以非事物方式执行操作，如果当前存在事物，就抛出异常。 PROPAGATION_NESTED(propagation_nested) 如果一个活动的事务存在，则运行在一个嵌套的事务中。如果没有活动事务，则按REQUIRED属性执行。它使用了一个单独的事务，这个事务拥有多个可以回滚的保存点。内部事务的回滚不会对外部事务造成影响。它只对DataSourceTransactionManager事务管理器起效。 数据库隔离级别 隔离级别 隔离级别的值 导致的问题 Read Uncommited 0 允许脏读，不可重复读，幻读 Read Commited 1 避免脏读，允许不可重复读和幻读 RepeatableRead 2 避免脏读和不可重复读，允许幻读 Serializable 3 避免脏读 ，不可重复读，幻读，事物一个一个执行，执行效率低 spring中的隔离级别 常量名称 常量解释 ISOLATION_DEFAULT(isolation_default) PlatfromTransactionManager默认的事物隔离级别，使用数据库默认的事物隔离级别。 ISOLATION_READ_UNCOMMITTED(isolation_read_uncommitted) 读未提交 ISOLATION_READ_COMMITTED(isolation_read_committed) 读已提交 ISOLATION_REPEATABLE_READ(isolation_repeatable) 可重复读 ISOLATION_SERIALIZABLE(isolation_serializable) 串行化 @Resource注解和@Autowired注解的区别 1.当单独使用@Autowired注解时，会默认按照类型装配，不适用与系统里一个接口有多个实现类的情况。2.当系统内存在多个实现类时，无法按照类型装配，@Autowired可以配合@Qualifier注解按照名称进行装配3.@Resource默认按照名称装配，可以通过指定name属性来进行按照名称来装配。4.@Resource若是指定的name为空串或者是未指定name属性，会去按照类型来装配(此时系统内只能存在一个接口实现类，否则报错)5.@Resource装配的类必须存在，否则会报错。@Autowired可以配置required=false来设置装配的bean是否是必须的。6.@Resource注解属于JSR250标准的注释，属于J2EE的。而@Autowired属于spring提供的注解。使用@Resource注解可以与spring解耦。 Restful风格 参考博客：https://blog.igevin.info/posts/restful-architecture-in-general/#restful_features 特点：资源，统一接口 ，URI和无状态 资源：就是网络上面的一个实体，或者说是网络上面的一个具体信息。 统一接口：数据的元操作，分别对应于http的四个不同的方法。 URI：可以通过一个URI访问一个具体的资源。 无状态： 为啥说spring mvc是线程安全的 ​ SpringMVC是基于方法的映射，每一个controller在容器中只有一个实例对象。若是我们在controller中使用一些共享变量时，可以使用ThreadLocal关键字来实现。但是尽量不要使用共享变量。 什么是一致性hash ​ 附上一篇比较白话的博客http://www.zsythink.net/archives/1182 为什么synchronized不能锁住基本数据类型 ​ synchronized的实现原理是在synchronized修饰的代码块的开始和结束的地方添加monitorenter和monitorexit两个字节码指令，这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。就是说每一个对象会有一个monitor对象，上锁时需要获取到这个monitor对象。 偏向锁-&gt;轻量级锁-&gt;重量级锁 获取偏向锁的流程： ​ 1. 当前线程首先会去检查对象的对象头信息中有没有存储线程id，如果没有存储线程id，设置当前线程id。 ​ 2.若是对象头中存储了线程id，当前线程会去通知该id的线程，进入到暂停状态，并将对象头线程id清空。 ​ 3.两个线程会将对象头信息拷贝到各自的栈中，并尝试使用cas操作将对象头指向该栈，操作成功执行。 4. 若是操作并成功执行自旋操作。 5. 若是在自旋指定的时间内，另一个线程执行完成了，会唤醒该自旋的线程来执行。 6. 若是在自旋的时间内，另一个线程没有执行完，自旋的线程会进入到阻塞状态。","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"spring","slug":"java/spring","permalink":"https://gzl2017.github.io/categories/java/spring/"}]},{"title":"redis","date":"2019-08-18T02:58:52.000Z","path":"wiki/redis/","text":"redis和zk实现分布式锁的区别 实现方式 优点 缺点 基于redis 性能高 锁的失效时间很难把控 基于zk 实现简单 有效解决单点问题 不可重入问题 锁无法释放问题 非阻塞问题 性能没redis高 对于临时节点的删除和创建需要leader节点来处理 然后同步给flow节点 cap原则 缓存数据的同步方式 先写入数据库，在写入缓存 查询数据库，然后写入缓存 定时刷新数据写入缓存 redis特点 一种缓存中间件 key-value的存储形式 默认16个db（0-15）个空间 支持数据的持久化 redis五种数据结构 数据结构 使用场景 string session共享 短信验证码 ip限制 序列自增 list 分布式队列 栈 hash 对象的存储（用户信息） set 用户标签(定点推送) 求交集 并集 sorted set 过期时间 消极方法 当应用访问key时，发现key已经过期，就会删除。 积极方法： 周期性的从设置了过期时间的key中选择一部分的key进行删除。 随机测试20个带有timeout信息的key。 如果超过25%的key被删除，则重复执行整个流程 pub/sub 发布订阅模式 redis持久化及原理 RDB 概念：当符合【条件】的时候，fork子进程，生成dump.rdb快照文件。 缺点：数据丢失 规则 配置规则，配置文件配置 save或者bgsave命令触发 flushall命令触发，且满足配置规则 执行复制操作 AOF 概念：需要配置文件开启(默认关闭)，aof文件的写入，只针对事物操作。AOF重写 缺点： 规则 redis内存回收策略 ​ redis单线程性能高的原因 内存和网络的宽带 多路复用（同一时间处理多个请求） 避免线程切换 纯内存操作 lua脚本在redis中的应用 pipeline管道模型 减少网络开销去执行多个指令 满足原子性 复用性 redis.call(“set”, “gupao”, “123”) redis.call(“get”, “gupao”); lua脚本可以存储在服务端-&gt;生成摘要 redis集群 解决单点问题 主从复制(master-slave) 数据同步: 全量复制(初始化) 增量复制 无磁盘复制 选主(哨兵) 哨兵机制 监控master和slave是否正常运行 当master出现故障的时候，从slave中选取一个新的master Redis-Cluster Redis的实践应用","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"数据库","slug":"java/数据库","permalink":"https://gzl2017.github.io/categories/java/数据库/"},{"name":"redis","slug":"java/数据库/redis","permalink":"https://gzl2017.github.io/categories/java/数据库/redis/"}]},{"title":"HashMap","date":"2019-08-16T14:01:46.000Z","path":"wiki/HashMap/","text":"1.HashMap的数据结构 在jdk1.7中基于数组+链表,在jdk1.8中基于数组+链表+红黑树 2.HashMap的put方法的过程 a.首先判断当前的数组是否被初始化,若是没有被初始化,调用resize方法初始化 b.通过key的hash值和数组长度计算出该元素在数组中的位置 c1.若是数组上没有元素,构建Node节点,存储该元素 c21.若是该数组上有元素,且第一个节点的key与要存储的key相等,用变量保存该节点。 c22.若是该数组上有元素,且第一个节点的key与要存储的key不相等,需要判断该节点类型。 若是该节点属于红黑树,将元素插入到红黑树。 若是该节点属于链表,循环遍历链表,若是没有遇到key相同的,将key-value创建称为节点,插入到链表的尾部。判断是否需要转成红黑树，若是需要，将链表转成红黑树。 d.前面的操作中，若是找到与key相同的节点,根据条件判断是否需要覆盖,若是需要覆盖,直接修改原有节点的value。 f.将元素的个数size加1并判断是否需要扩容,若是需要扩容,调用resize方法扩容。 3.HashMap的resize方法 resize方法涉及到两个大的步骤,首先是确定新数组的大小已经下次的扩容时机，新数组大小为原有数组大小的两倍，扩容变量也扩大为原有的两倍。其次是将原有数组的元素迁移至新的数组中,其中数组元素只会在两个地方，一个在[原下标]的地方，另一个在[原下标+原容量]的位置。","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"源码","slug":"java/源码","permalink":"https://gzl2017.github.io/categories/java/源码/"}]},{"title":"jvm","date":"2019-08-16T04:51:03.000Z","path":"wiki/jvm/","text":"jvm的运行时数据区 堆:java垃圾回收的主要区域，唯一存在的价值就是存放对象实例，几乎所有的对象实例都会在这里分配内存。从垃圾回收的角度分为新生代和老年代。在细分一点可以划分为Eden空间,From Survivor空间,To Survivor空间。若是在堆中没有完成实例分配，并且堆也无法再扩展时，就会抛出OutOfMemoryError异常。 方法区:用于存储已经被虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。当方法区无法满足内存分配的需求时，将会抛出OutOfMemoryError异常。 虚拟机栈:描述的是java方法执行的内存模型，每个方法执行时都会创建一个栈帧，栈帧中用于存储局部变量表，操作数栈，动态链接，方法出口等信息。当线程申请的栈深度大于虚拟机所允许的栈深度，将抛出StackOverflowError异常。若是虚拟机动态扩展时无法申请到足够的内存，将会抛出OutOfMemoryError异常。 程序计数器:记录当前线程执行的字节码指令的行号，不会发生OutOfMemoryError。 本地方法栈:用于执行非java方法的内存模型，也会发生StackOverflowError和OutOfMemoryError异常。 jvm垃圾回收考虑的三个问题 回收哪些对象 什么时候回收这些对象 怎么回收这些对象 jvm垃圾回收算法 标记清除：会有内存碎片 标记整理：没有内存碎片，适合新生代对象的回收 复制算法：需要留出一部分的内存空间，利用率不高 分代收集算法：新生代死亡对象多，采用复制算法。老年代死亡对象少，采用标记整理或标记清除。 jvm垃圾收集器 ​ 新生代垃圾收集器 ​ 老年代垃圾收集器","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"jvm","slug":"java/jvm","permalink":"https://gzl2017.github.io/categories/java/jvm/"}]},{"title":"面试题","date":"2019-08-15T12:56:11.000Z","path":"wiki/mysql/","text":"1.char(32)和varchar(32)的区别 (1):char和varchar都是数据库定义字符串类型的数据格式,char是一种定长度的类型,varchar是一种可变长度的类型。 (2):char(32)表示定义了当前字段所占用的存储空间为32个字符,不管字段长度是否达到32,占用的空间是不变的。而varchar(32)表示定义了当前字段所能够占用的最大存储空间是32个字符,实际占用空间是字段的大小。 (3):就存储效率而言,定长的char类型由于一开始就定义好了字段占用空间,不需要根据字段的长度在去申请空间,故效率相对较高,但是在占用空间上就没有varchar有优势。而varchar由于根据字段长度调整空间占用,故空间消耗较小,但是存储效率不高。 2.sql注入,如何避免sql注入概念: 所谓sql注入, 就是攻击者将sql命令插入到web表单的输入域或者是页面请求的查询字符串，欺骗服务器执行恶意的sql命令。(某些表单中的输入命令被直接用来构造(或影响)sql命令，或者是构成存储过程的输入参数, 这类表单特别容易受到sql注入式攻击)。 如何避免: (1): mybatis中多使用[#{param}],尽量避免使用[${param}],原因在于[${param}]会直接参与sql编译,容易造成sql攻击。 3.数据库的三大范式 第一范式: 每一列都是一个不可再分割的属性值,确保每一列的原子性(规范列)。 第二范式: 在满足第一范式的要求下，每一行数据只做一件事(规范行)。 第三范式: 在满足第二范式的要求下，确保数据表中的每一列数据都和主键直接相关,而不能够间接相关。","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://gzl2017.github.io/categories/java/"},{"name":"数据库","slug":"java/数据库","permalink":"https://gzl2017.github.io/categories/java/数据库/"},{"name":"mysql","slug":"java/数据库/mysql","permalink":"https://gzl2017.github.io/categories/java/数据库/mysql/"}]}]}